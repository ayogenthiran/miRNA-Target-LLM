{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ayogenth/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = \"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\"\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from tdc.multi_pred import MTI\n",
    "\n",
    "# Load the miRTarBase dataset\n",
    "data = MTI(name='miRTarBase')\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "split = data.get_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>miRNA_ID</th>\n",
       "      <th>miRNA</th>\n",
       "      <th>Target_ID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath-miR398c-3p</td>\n",
       "      <td>UGUGUUCUCAGGUCACCCCUG</td>\n",
       "      <td>817365</td>\n",
       "      <td>MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath-miR398b-3p</td>\n",
       "      <td>UGUGUUCUCAGGUCACCCCUG</td>\n",
       "      <td>817365</td>\n",
       "      <td>MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath-miR398b-3p</td>\n",
       "      <td>UGUGUUCUCAGGUCACCCCUG</td>\n",
       "      <td>837405</td>\n",
       "      <td>MAKGVAVLNSSEGVTGTIFFTQEGDGVTTVSGTVSGLKPGLHGFHV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath-miR398a-3p</td>\n",
       "      <td>UGUGUUCUCAGGUCACCCCUU</td>\n",
       "      <td>817365</td>\n",
       "      <td>MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath-miR398a-3p</td>\n",
       "      <td>UGUGUUCUCAGGUCACCCCUU</td>\n",
       "      <td>837405</td>\n",
       "      <td>MAKGVAVLNSSEGVTGTIFFTQEGDGVTTVSGTVSGLKPGLHGFHV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         miRNA_ID                  miRNA  Target_ID  \\\n",
       "0  ath-miR398c-3p  UGUGUUCUCAGGUCACCCCUG     817365   \n",
       "1  ath-miR398b-3p  UGUGUUCUCAGGUCACCCCUG     817365   \n",
       "2  ath-miR398b-3p  UGUGUUCUCAGGUCACCCCUG     837405   \n",
       "3  ath-miR398a-3p  UGUGUUCUCAGGUCACCCCUU     817365   \n",
       "4  ath-miR398a-3p  UGUGUUCUCAGGUCACCCCUU     837405   \n",
       "\n",
       "                                              Target  Y  \n",
       "0  MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...  1  \n",
       "1  MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...  1  \n",
       "2  MAKGVAVLNSSEGVTGTIFFTQEGDGVTTVSGTVSGLKPGLHGFHV...  1  \n",
       "3  MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...  1  \n",
       "4  MAKGVAVLNSSEGVTGTIFFTQEGDGVTTVSGTVSGLKPGLHGFHV...  1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>miRNA_ID</th>\n",
       "      <th>miRNA</th>\n",
       "      <th>Target_ID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hsa-miR-664a-3p</td>\n",
       "      <td>UAUUCAUUUAUCCCCAGCCUACA</td>\n",
       "      <td>10447</td>\n",
       "      <td>MRVAGAAKLVVAVAVFLLTFYVISQVFEIKMDASLGNLFARSALDT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hsa-miR-5186</td>\n",
       "      <td>AGAGAUUGGUAGAAAUCAGGU</td>\n",
       "      <td>1399</td>\n",
       "      <td>MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hsa-miR-665</td>\n",
       "      <td>ACCAGGAGGCUGAGGCCCCU</td>\n",
       "      <td>91869</td>\n",
       "      <td>MGSQEVLGHAARLASSGLLLQVLFRLITFVLNAFILRFLSKEIVGV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hsa-miR-4284</td>\n",
       "      <td>GGGCUCACAUCACCCCAU</td>\n",
       "      <td>160760</td>\n",
       "      <td>MFSVLSYGRLVARAVLGGLSQTDPRAGGGGGGDYGLVTAGCGFGKD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hsa-miR-3125</td>\n",
       "      <td>UAGAGGAAGCUGUGGAGAGA</td>\n",
       "      <td>10949</td>\n",
       "      <td>MENSQLCKLFIGGLNVQTSESGLRGHFEAFGTLTDCVVVVNPQTKR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          miRNA_ID                    miRNA  Target_ID  \\\n",
       "0  hsa-miR-664a-3p  UAUUCAUUUAUCCCCAGCCUACA      10447   \n",
       "1     hsa-miR-5186    AGAGAUUGGUAGAAAUCAGGU       1399   \n",
       "2      hsa-miR-665     ACCAGGAGGCUGAGGCCCCU      91869   \n",
       "3     hsa-miR-4284       GGGCUCACAUCACCCCAU     160760   \n",
       "4     hsa-miR-3125     UAGAGGAAGCUGUGGAGAGA      10949   \n",
       "\n",
       "                                              Target  Y  \n",
       "0  MRVAGAAKLVVAVAVFLLTFYVISQVFEIKMDASLGNLFARSALDT...  1  \n",
       "1  MSSARFDSSDRSAWYMGPVSRQEAQTRLQGQRHGMFLVRDSSTCPG...  1  \n",
       "2  MGSQEVLGHAARLASSGLLLQVLFRLITFVLNAFILRFLSKEIVGV...  1  \n",
       "3  MFSVLSYGRLVARAVLGGLSQTDPRAGGGGGGDYGLVTAGCGFGKD...  1  \n",
       "4  MENSQLCKLFIGGLNVQTSESGLRGHFEAFGTLTDCVVVVNPQTKR...  1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a few rows of the training and test data\n",
    "\n",
    "display(split['train'].head())\n",
    "\n",
    "display(split['test'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.concat([split['train'], split['valid']])\n",
    "\n",
    "# Keep only the necessary columns\n",
    "df = df[['miRNA', 'Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target sequence length statistics:\n",
      "Minimum: 24\n",
      "Maximum: 34350\n",
      "Mean: 601.90\n",
      "Median: 469.0\n",
      "99th percentile: 2602.0\n",
      "\n",
      "Original dataset shape: (320066, 4)\n",
      "Cleaned dataset shape: (316869, 4)\n",
      "Number of outliers removed: 3197\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate lengths of original sequences\n",
    "df['miRNA_length'] = df['miRNA'].str.len()\n",
    "df['Target_length'] = df['Target'].str.len()\n",
    "\n",
    "# Analyze Target sequence lengths\n",
    "percentile_99 = np.percentile(df['Target_length'], 99)\n",
    "\n",
    "print(f\"Target sequence length statistics:\")\n",
    "print(f\"Minimum: {df['Target_length'].min()}\")\n",
    "print(f\"Maximum: {df['Target_length'].max()}\")\n",
    "print(f\"Mean: {df['Target_length'].mean():.2f}\")\n",
    "print(f\"Median: {df['Target_length'].median()}\")\n",
    "print(f\"99th percentile: {percentile_99}\")\n",
    "\n",
    "# Remove extreme outliers (top 1%)\n",
    "df_cleaned = df[df['Target_length'] <= percentile_99]\n",
    "\n",
    "print(f\"\\nOriginal dataset shape: {df.shape}\")\n",
    "print(f\"Cleaned dataset shape: {df_cleaned.shape}\")\n",
    "print(f\"Number of outliers removed: {df.shape[0] - df_cleaned.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Target_length'], bins=100, edgecolor='black')\n",
    "plt.axvline(percentile_99, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.title('Distribution of Target Sequence Lengths')\n",
    "plt.xlabel('Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('target_length_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset sequence length statistics:\n",
      "miRNA - Min: 16, Max: 28, Mean: 21.67\n",
      "Target - Min: 24, Max: 2602, Mean: 570.50\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned data\n",
    "df_cleaned.to_csv('miRNA_data_cleaned.csv', index=False)\n",
    "\n",
    "# Print sequence length statistics for cleaned data\n",
    "print(\"\\nCleaned dataset sequence length statistics:\")\n",
    "print(f\"miRNA - Min: {df_cleaned['miRNA_length'].min()}, Max: {df_cleaned['miRNA_length'].max()}, Mean: {df_cleaned['miRNA_length'].mean():.2f}\")\n",
    "print(f\"Target - Min: {df_cleaned['Target_length'].min()}, Max: {df_cleaned['Target_length'].max()}, Mean: {df_cleaned['Target_length'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>miRNA</th>\n",
       "      <th>Target</th>\n",
       "      <th>miRNA_length</th>\n",
       "      <th>Target_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UGUGUUCUCAGGUCACCCCUG</td>\n",
       "      <td>MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...</td>\n",
       "      <td>21</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UGUGUUCUCAGGUCACCCCUG</td>\n",
       "      <td>MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...</td>\n",
       "      <td>21</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UGUGUUCUCAGGUCACCCCUG</td>\n",
       "      <td>MAKGVAVLNSSEGVTGTIFFTQEGDGVTTVSGTVSGLKPGLHGFHV...</td>\n",
       "      <td>21</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UGUGUUCUCAGGUCACCCCUU</td>\n",
       "      <td>MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...</td>\n",
       "      <td>21</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UGUGUUCUCAGGUCACCCCUU</td>\n",
       "      <td>MAKGVAVLNSSEGVTGTIFFTQEGDGVTTVSGTVSGLKPGLHGFHV...</td>\n",
       "      <td>21</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40002</th>\n",
       "      <td>UGCUGAGGUCCGGGCUGUGCC</td>\n",
       "      <td>MASSETEIRWAEPGLGKGPQRRRWAWAEDKRDVDRSSSQSWEEERL...</td>\n",
       "      <td>21</td>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40003</th>\n",
       "      <td>AGGAGGAUGGAGAGCUGGGCCAGA</td>\n",
       "      <td>MEVEAVCGGAGEVEAQDSDPAPAFSKAPGSAGHYELPWVEKYRPVK...</td>\n",
       "      <td>24</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40004</th>\n",
       "      <td>AAAAGUGCUUACAGUGCAGGUAG</td>\n",
       "      <td>MVLAAAMSQDADPSGPEQPDRVACSVPGARASPAPSGPRGMQQPPP...</td>\n",
       "      <td>23</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40005</th>\n",
       "      <td>GAAAGUACAGAUCGGAUGGGU</td>\n",
       "      <td>MAEVGEDSGARALLALRSAPCSPVLCAAAAAAAFPAAAPPPAPAQP...</td>\n",
       "      <td>21</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40006</th>\n",
       "      <td>ACUUUCCUCACUCCCGUGAAGU</td>\n",
       "      <td>MDKLKKVLSGQDTEDRSGLSEVVEASSLSWSTRIKGFIACFAIGIL...</td>\n",
       "      <td>22</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316868 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          miRNA  \\\n",
       "0         UGUGUUCUCAGGUCACCCCUG   \n",
       "1         UGUGUUCUCAGGUCACCCCUG   \n",
       "2         UGUGUUCUCAGGUCACCCCUG   \n",
       "3         UGUGUUCUCAGGUCACCCCUU   \n",
       "4         UGUGUUCUCAGGUCACCCCUU   \n",
       "...                         ...   \n",
       "40002     UGCUGAGGUCCGGGCUGUGCC   \n",
       "40003  AGGAGGAUGGAGAGCUGGGCCAGA   \n",
       "40004   AAAAGUGCUUACAGUGCAGGUAG   \n",
       "40005     GAAAGUACAGAUCGGAUGGGU   \n",
       "40006    ACUUUCCUCACUCCCGUGAAGU   \n",
       "\n",
       "                                                  Target  miRNA_length  \\\n",
       "0      MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...            21   \n",
       "1      MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...            21   \n",
       "2      MAKGVAVLNSSEGVTGTIFFTQEGDGVTTVSGTVSGLKPGLHGFHV...            21   \n",
       "3      MAATNTILAFSSPSRLLIPPSSNPSTLRSSFRGVSLNNNNLHRLQS...            21   \n",
       "4      MAKGVAVLNSSEGVTGTIFFTQEGDGVTTVSGTVSGLKPGLHGFHV...            21   \n",
       "...                                                  ...           ...   \n",
       "40002  MASSETEIRWAEPGLGKGPQRRRWAWAEDKRDVDRSSSQSWEEERL...            21   \n",
       "40003  MEVEAVCGGAGEVEAQDSDPAPAFSKAPGSAGHYELPWVEKYRPVK...            24   \n",
       "40004  MVLAAAMSQDADPSGPEQPDRVACSVPGARASPAPSGPRGMQQPPP...            23   \n",
       "40005  MAEVGEDSGARALLALRSAPCSPVLCAAAAAAAFPAAAPPPAPAQP...            21   \n",
       "40006  MDKLKKVLSGQDTEDRSGLSEVVEASSLSWSTRIKGFIACFAIGIL...            22   \n",
       "\n",
       "       Target_length  \n",
       "0                216  \n",
       "1                216  \n",
       "2                152  \n",
       "3                216  \n",
       "4                152  \n",
       "...              ...  \n",
       "40002           1439  \n",
       "40003            354  \n",
       "40004           1227  \n",
       "40005            733  \n",
       "40006            160  \n",
       "\n",
       "[316868 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_cleaned[[\"miRNA\", \"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CUUUGAGCACAUGAGCAGACGGA',\n",
       " 'MEEKPGQPQPQHHHSHHHPHHHPQQQQQQPHHHHHYYFYNHSHNHHHHHHHQQPHQYLQHGAEGSPKAQPKPLKHEQKHTLQQHQETPKKKTGYGELNGNAGEREISLKNLSSDEATNPISRVLNGNQQVVDTSLKQTVKANTFGKAGIKTKNFIQKNSMDKKNGKSYENKSGENQSVDKSDTIPIPNGVVTNNSGYITNGYMGKGADNDGSGSESGYTTPKKRKARRNSAKGCENLNIVQDKIMQQETSVPTLKQGLETFKPDYSEQKGNRVDGSKPIWKYETGPGGTSRGKPAVGDMLRKSSDSKPGVSSKKFDDRPKGKHASAVASKEDSWTLFKPPPVFPVDNSSAKIVPKISYASKVKENLNKTIQNSSVSPTSSSSSSSSTGETQTQSSSRLSQVPMSALKSVTSANFSNGPVLAGTDGNVYPPGGQPLLTTAANTLTPISSGTDSVLQDMSLTSAAVEQIKTSLFIYPSNMQTMLLSTAQVDLPSQTDQQNLGDIFQNQWGLSFINEPSAGPETVTGKSSEHKVMEVTFQGEYPATLVSQGAEIIPSGTEHPVFPKAYELEKRTSPQVLGSILKSGTTSESGALSLEPSHIGDLQKADTSSQGALVFLSKDYEIESQNPLASPTNTLLGSAKEQRYQRGLERNDSWGSFDLRAAIVYHTKEMESIWNLQKQDPKRIITYNEAMDSPDQ')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[\"miRNA\"][116858], df_final[\"Target\"][116858]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.8: Fast Mistral patching. Transformers = 4.44.0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.642 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 1700 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
    "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
    "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3-mini-4k-instruct\",          # Phi-3 2x faster!d\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "mistral_model, mistral_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/mistral-7b-v0.3-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "mistral_model = FastLanguageModel.get_peft_model(\n",
    "    mistral_model,\n",
    "    r = 128, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916a00820c1b490aa7bf05b1fe8658c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/316869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert DataFrame to Dataset\n",
    "dataset = Dataset.from_pandas(df_final)\n",
    "\n",
    "# Improved prompt template\n",
    "miRNA_prompt = \"\"\"As a molecular biologist, your task is to predict a microRNA (miRNA) sequence that will effectively bind to and regulate the following gene target sequence. Consider these key points:\n",
    "\n",
    "1. miRNAs are typically 19-25 nucleotides long.\n",
    "2. The seed region (positions 2-8) is crucial for target recognition.\n",
    "3. Perfect complementarity isn't necessary; some mismatches are common.\n",
    "4. The 3' end of the miRNA often has less perfect base pairing.\n",
    "\n",
    "Gene Target Sequence:\n",
    "{}\n",
    "\n",
    "Predicted miRNA Sequence:\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "# Define EOS_TOKEN (replace with your actual EOS token)\n",
    "EOS_TOKEN = \"<|endoftext|>\"\n",
    "\n",
    "# Generic instruction for the entire dataset\n",
    "GENERIC_INSTRUCTION = \"Predict miRNA sequences that will effectively bind to and regulate the given gene target sequences, considering miRNA structure and binding principles.\"\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    targets = examples[\"Target\"]\n",
    "    miRNAs = examples[\"miRNA\"]\n",
    "    texts = []\n",
    "    for target, miRNA in zip(targets, miRNAs):\n",
    "        text = miRNA_prompt.format(target, miRNA) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts,}\n",
    "pass\n",
    "\n",
    "# Apply the formatting function\n",
    "train_dataset = dataset.map(formatting_prompts_func, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7546dcdc4644d38de65094f238e40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/316869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = mistral_model,\n",
    "    tokenizer = mistral_tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "         #max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4090. Max memory = 23.642 GB.\n",
      "5.605 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 316,869 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 335,544,320\n",
      "Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n",
      "\tper_device_train_batch_size: 8 (from args) != 2 (from trainer_state.json)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:02, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>3.320400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_mistral/tokenizer_config.json',\n",
       " 'lora_mistral/special_tokens_map.json',\n",
       " 'lora_mistral/tokenizer.model',\n",
       " 'lora_mistral/added_tokens.json',\n",
       " 'lora_mistral/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_model.save_pretrained(\"lora_mistral\") # Local saving\n",
    "mistral_tokenizer.save_pretrained(\"lora_mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Mistral patching. Transformers = 4.44.0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.642 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"lora_mistral\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "FastLanguageModel.for_inference(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> As a molecular biologist, your task is to predict a microRNA (miRNA) sequence that will effectively bind to and regulate the following gene target sequence. Consider these key points:\n",
      "\n",
      "1. miRNAs are typically 19-25 nucleotides long.\n",
      "2. The seed region (positions 2-8) is crucial for target recognition.\n",
      "3. Perfect complementarity isn't necessary; some mismatches are common.\n",
      "4. The 3' end of the miRNA often has less perfect base pairing.\n",
      "\n",
      "Gene Target Sequence:\n",
      "MEEKPGQPQPQHHHSHHHPHHHPQQQQQQPHHHHHYYFYNHSHNHHHHHHHQQPHQYLQHGAEGSPKAQPKPLKHEQKHTLQQHQETPKKKTGYGELNGNAGEREISLKNLSSDEATNPISRVLNGNQQVVDTSLKQTVKANTFGKAGIKTKNFIQKNSMDKKNGKSYENKSGENQSVDKSDTIPIPNGVVTNNSGYITNGYMGKGADNDGSGSESGYTTPKKRKARRNSAKGCENLNIVQDKIMQQETSVPTLKQGLETFKPDYSEQKGNRVDGSKPIWKYETGPGGTSRGKPAVGDMLRKSSDSKPGVSSKKFDDRPKGKHASAVASKEDSWTLFKPPPVFPVDNSSAKIVPKISYASKVKENLNKTIQNSSVSPTSSSSSSSSTGETQTQSSSRLSQVPMSALKSVTSANFSNGPVLAGTDGNVYPPGGQPLLTTAANTLTPISSGTDSVLQDMSLTSAAVEQIKTSLFIYPSNMQTMLLSTAQVDLPSQTDQQNLGDIFQNQWGLSFINEPSAGPETVTGKSSEHKVMEVTFQGEYPATLVSQGAEIIPSGTEHPVFPKAYELEKRTSPQVLGSILKSGTTSESGALSLEPSHIGDLQKADTSSQGALVFLSKDYEIESQNPLASPTNTLLGSAKEQRYQRGLERNDSWGSFDLRAAIVYHTKEMESIWNLQKQDPKRIITYNEAMDSPDQ\n",
      "\n",
      "Predicted miRNA Sequence:\n",
      "\n",
      "UGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAGGAG\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "[\n",
    "    miRNA_prompt.format(\n",
    "        \"MEEKPGQPQPQHHHSHHHPHHHPQQQQQQPHHHHHYYFYNHSHNHHHHHHHQQPHQYLQHGAEGSPKAQPKPLKHEQKHTLQQHQETPKKKTGYGELNGNAGEREISLKNLSSDEATNPISRVLNGNQQVVDTSLKQTVKANTFGKAGIKTKNFIQKNSMDKKNGKSYENKSGENQSVDKSDTIPIPNGVVTNNSGYITNGYMGKGADNDGSGSESGYTTPKKRKARRNSAKGCENLNIVQDKIMQQETSVPTLKQGLETFKPDYSEQKGNRVDGSKPIWKYETGPGGTSRGKPAVGDMLRKSSDSKPGVSSKKFDDRPKGKHASAVASKEDSWTLFKPPPVFPVDNSSAKIVPKISYASKVKENLNKTIQNSSVSPTSSSSSSSSTGETQTQSSSRLSQVPMSALKSVTSANFSNGPVLAGTDGNVYPPGGQPLLTTAANTLTPISSGTDSVLQDMSLTSAAVEQIKTSLFIYPSNMQTMLLSTAQVDLPSQTDQQNLGDIFQNQWGLSFINEPSAGPETVTGKSSEHKVMEVTFQGEYPATLVSQGAEIIPSGTEHPVFPKAYELEKRTSPQVLGSILKSGTTSESGALSLEPSHIGDLQKADTSSQGALVFLSKDYEIESQNPLASPTNTLLGSAKEQRYQRGLERNDSWGSFDLRAAIVYHTKEMESIWNLQKQDPKRIITYNEAMDSPDQ\", # instruction\n",
    "        \"\", # input\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUUUGAGCACAUGAGCAGACGGA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miRNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
